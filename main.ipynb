{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "\n",
    "#Neural network libraries\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# #Creating optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# For terminating program (useful for stopping before training is complete and seeing entire result)\n",
    "import signal\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                 problem\n",
      "1       The construction industry is indubitably one o...\n",
      "2       I'm sure you, like me, are feeling the heat - ...\n",
      "3       The massive shift in student learning towards ...\n",
      "4       The fashion industry is one of the top contrib...\n",
      "                              ...                        \n",
      "1296    The linear 'take, make, dispose' model of prod...\n",
      "1297    The conundrum we face is the improper disposal...\n",
      "1298               This solution will help the vegetation\n",
      "1299    Accumulation and improper disposal of single-u...\n",
      "1300    The excessive and wasteful resource consumptio...\n",
      "Name: 1, Length: 1301, dtype: object\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.path.abspath('') # absolute file path in Jupyter\n",
    "file_path = os.path.join(script_dir, \"AI EarthHack Dataset.csv\") # file path for the text file input\n",
    "\n",
    "dataset = pd.read_csv(file_path, header=None)\n",
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Relevance:': [0.9870656728744507], 'Feasibility': [0.8657248616218567], 'Innovation:': [0.7322619557380676], 'Scalability': [0.5536961555480957]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# TODO look into changing the modle, bart-large-mnli seems to be the most populat for ZSC\n",
    "# Other options are T5, GPT, and RoBERTa\n",
    "\n",
    "# Models tried:\n",
    "# - facebook/bart-large-mnli\n",
    "# - sjrhuschlee/flan-t5-base-mnli\n",
    "# - google/flan-t5-base\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"sjrhuschlee/flan-t5-base-mnli\")\n",
    "\n",
    "# Example class descriptions and input text\n",
    "# input_text = [[\"Problem: \"+str(dataset[1][i]), \"Solution: \"+str(dataset[2][i])] for i in range(1,3)]\n",
    "# Bad solutions: 39, 52, 22\n",
    "# Good solutions: 3, 117\n",
    "\n",
    "input_text = \"Problem: \" + str(dataset[1][39]) + \" Solution: \" + str(dataset[2][39])\n",
    "\n",
    "class_descriptions1 = [\n",
    "    \"A problem-solution pair in which the solution is innovative, relevant to the problem, feasible, specific, and actionable\",\n",
    "    \"A problem-solution pair in which the solution is relevant to the problem, but not necessarily innovative, feasible, specific, or actionable\",\n",
    "    \"A problem-solution pair in which the solution is irrelevant, non-specific, not feasible, or not detailed\"\n",
    "]\n",
    "\n",
    "class_descriptions2=[\n",
    "    \"The solution is relevant to the problem\",\n",
    "    \"The solution is not relevant to the problem\"\n",
    "]\n",
    "\n",
    "class_descriptions3=[\n",
    "    \"The solution is feasible\",\n",
    "    \"The solution is not feasible\"\n",
    "]\n",
    "\n",
    "class_descriptions4=[\n",
    "    \"The solution is innovative\",\n",
    "    \"The solution is not innovative\"\n",
    "]\n",
    "\n",
    "class_descriptions5 = [\n",
    "    \"The solution is scalable\",\n",
    "    \"The solution is not scalable\"\n",
    "]\n",
    "\n",
    "all_descriptions = {\n",
    "    \"Relevance:\": class_descriptions2,\n",
    "    \"Feasibility\": class_descriptions3,\n",
    "    \"Innovation:\": class_descriptions4,\n",
    "    \"Scalability\": class_descriptions5\n",
    "}\n",
    "\n",
    "scores = {\n",
    "    \"Relevance:\": [],\n",
    "    \"Feasibility\": [],\n",
    "    \"Innovation:\": [],\n",
    "    \"Scalability\": []\n",
    "}\n",
    "\n",
    "for i in range(7,8):\n",
    "    input_text = \"Problem: \" + str(dataset[1][i]) + \" Solution: \" + str(dataset[2][i])\n",
    "    for category in all_descriptions:\n",
    "        result = classifier(input_text, all_descriptions[category])\n",
    "        for label,score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "            if label==all_descriptions[category][0]:\n",
    "                scores[category].append(score)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
