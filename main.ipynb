{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "\n",
    "#Neural network libraries\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# #Creating optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# For terminating program (useful for stopping before training is complete and seeing entire result)\n",
    "import signal\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                 problem\n",
      "1       The construction industry is indubitably one o...\n",
      "2       I'm sure you, like me, are feeling the heat - ...\n",
      "3       The massive shift in student learning towards ...\n",
      "4       The fashion industry is one of the top contrib...\n",
      "                              ...                        \n",
      "1296    The linear 'take, make, dispose' model of prod...\n",
      "1297    The conundrum we face is the improper disposal...\n",
      "1298               This solution will help the vegetation\n",
      "1299    Accumulation and improper disposal of single-u...\n",
      "1300    The excessive and wasteful resource consumptio...\n",
      "Name: 1, Length: 1301, dtype: object\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.path.abspath('') # absolute file path in Jupyter\n",
    "file_path = os.path.join(script_dir, \"AI EarthHack Dataset.csv\") # file path for the text file input\n",
    "\n",
    "dataset = pd.read_csv(file_path, header=None)\n",
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# TODO look into changing the modle, bart-large-mnli seems to be the most populat for ZSC\n",
    "# Other options are T5, GPT, and RoBERTa\n",
    "\n",
    "# Models tried:\n",
    "# - facebook/bart-large-mnli\n",
    "# - sjrhuschlee/flan-t5-base-mnli\n",
    "# - google/flan-t5-base\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"sjrhuschlee/flan-t5-base-mnli\")\n",
    "\n",
    "# Example class descriptions and input text\n",
    "# input_text = [[\"Problem: \"+str(dataset[1][i]), \"Solution: \"+str(dataset[2][i])] for i in range(1,3)]\n",
    "# Bad solutions: 39, 52, 22, 457, 279\n",
    "# Good solutions: 3, 117\n",
    "\n",
    "#region Descriptions\n",
    "\n",
    "relevance_description=[\n",
    "    \"\"\"The problem and solution are detailed, specific, and in-depth.\n",
    "    Bonus points if they are related to circular economy.\"\"\",\n",
    "\n",
    "    \"\"\"The problem and/or solution are sloppy, off-topic (i.e., not sustainability related), unsuitable, or vague (such as the over-generic content that prioritizes form over substance, offering generalities instead of specific details).\n",
    "    In addition, inputs such as, 'Problem: I will research to make solution Solution: Hi' belong in this category.\"\"\"\n",
    "]\n",
    "\n",
    "feasibility_description=[\n",
    "    \"The solution is feasible.\",\n",
    "\n",
    "    \"\"\"The solution is not feasible.\n",
    "    This can mean that the solution is too wide in scope to be easily implemented, or puts unreasonable expectations on people, businesses, or the world as a whole.\n",
    "    Any solution that would take a large amount of resources or manpower to execute successfully would also be considered not feasible.\"\"\"\n",
    "]\n",
    "\n",
    "innovation_description=[\n",
    "    \"\"\"The solution is innovative.\n",
    "    A solution is innovative if it imagines something completely new and novel.\"\"\",\n",
    "\n",
    "    \"\"\"The solution is not innovative.\n",
    "    A solution is considered not innovative if it does not present any originality.\"\"\"\n",
    "]\n",
    "\n",
    "scalability_description = [\n",
    "    \"\"\"The solution is scalable.\n",
    "    A scalable solution will often provide a clear path on how the solution can be scaled in the future, if required.\n",
    "    A scalable solution is one that can start small, and grows to have a larger area of effect over time.\"\"\",\n",
    "\n",
    "    \"\"\"The solution is not scalable.\n",
    "    These solutions are ones that only focus on the small scale, and could not easily be done on a large scale.\"\"\"\n",
    "]\n",
    "\n",
    "circularEconomic_description = [\n",
    "    \"\"\"The solution is not pertinent to a circular economy.\n",
    "    In todayâ€™s rapidly evolving world, climate change stands as a formidable problem, deeply influencing our daily lives and the health of our planet. The circular economy, with its focus on reusing and recycling resources to minimize waste, emerges as a crucial strategy in this battle. Innovations like car-sharing platforms significantly reduce the carbon footprint of transportation, while modular designs in various products promote waste reduction by allowing individual components to be upgraded rather than discarding the entire item.\n",
    "    In the face of climate change's criticality, the urgency to identify and implement high-impact circular economy solutions has never been greater. The challenge we confront today, however, extends beyond coming up with solutions to confront this problem. It lies in the daunting task of effectively evaluating a vast and diverse array of solutions, discerning the most impactful ones amidst a sea of possibilities. This process can be overwhelming, given the complexity and the sheer volume of potential solutions, leading to cognitive overload for human evaluators.\"\"\",\n",
    "\n",
    "    \"The solution is not pertinent to a circular economy.\"\n",
    "]\n",
    "\n",
    "descriptions = {\n",
    "    \"Relevance\": relevance_description,\n",
    "    \"Feasibility\": feasibility_description,\n",
    "    \"Innovation\": innovation_description,\n",
    "    \"Scalability\": scalability_description,\n",
    "    \"Circular Economic\": circularEconomic_description\n",
    "}\n",
    "\n",
    "#endregion\n",
    "\n",
    "# CSV Sacrifices\n",
    "problems = []\n",
    "solutions = []\n",
    "scores = {\n",
    "    \"Relevance\": [],\n",
    "    \"Feasibility\": [],\n",
    "    \"Innovation\": [],\n",
    "    \"Scalability\": [],\n",
    "    \"Circular Economic\": []\n",
    "}\n",
    "\n",
    "# Determined through testing\n",
    "RELEVANCE_CUTOFF = 0.75\n",
    "\n",
    "start_row = 1\n",
    "end_row = 10\n",
    "\n",
    "rows_removed = 0\n",
    "\n",
    "# Go from line start_row to end_row\n",
    "for i in range(start_row, end_row + 1):\n",
    "\n",
    "    # Get the next problem and solution, slightly cleaned up\n",
    "    problem_text = str(dataset[1][i]).replace(\"\\\"\\\"\\\"\\\"\", \"\\\"\").strip()\n",
    "    solution_text = str(dataset[2][i]).replace(\"\\\"\\\"\\\"\\\"\", \"\\\"\").strip()\n",
    "\n",
    "    # Loop for each metric the AI should measure\n",
    "    for category in descriptions:\n",
    "\n",
    "        # Pass the problem and solution into the AI model, and let it determine the metric percentage using the prompts defined above\n",
    "        result = classifier(\"Problem: \" + problem_text + \" Solution: \" + solution_text, descriptions[category])\n",
    "\n",
    "        # Append the score of the metric to the scores dictionary\n",
    "        scores[category].append(result[\"scores\"][0]) if (result[\"labels\"][0] == descriptions[category][0]) else scores[category].append(result[\"scores\"][1])\n",
    "        \n",
    "        # If the relevance score is less than the cutoff, don't include it in the new CSV\n",
    "        if(category == \"Relevance\" and scores[category][i - start_row - rows_removed] < RELEVANCE_CUTOFF):\n",
    "            scores[category].pop()\n",
    "            rows_removed += 1\n",
    "            break\n",
    "    else:\n",
    "        problems.append(problem_text)\n",
    "        solutions.append(solution_text)\n",
    "\n",
    "print(len(problems))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting in another CSV\n",
    "obj = {'Id':range(1, len(problems)+1), 'Problem':problems, 'Solution':solutions}\n",
    "obj.update(scores)\n",
    "df = pd.DataFrame(obj)\n",
    "\n",
    "new_csv = 'Analyzed_dataset.csv'\n",
    "script_dir = os.path.abspath('')\n",
    "file_path = os.path.join(script_dir,new_csv)\n",
    "df.to_csv(file_path,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
